llm = newLLM({})
llm.add_user_prompt("vocÃª ta funcionandos  ?")
response = llm.generate()
print("Response: " .. response)